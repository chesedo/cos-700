\section{Metaprogramming}
Metaprogramming is a program that writes another program.
Like a normal program that operates on data, a metaprogram treats a program as its data \cite{savidis_19_01, anggoro_17_01, sheard_01_01}.
This makes a metaprogram like any normal program.
Like a normal program, a metaprogram can be refactored, abstracted, turned into library helpers, and tested \cite{lilis_15_01}.
Being able to write a program using code opens up many uses.

% TODO: reorder sections to remove this
\begin{notebox}
	This report will use the phrase ``meta code'' to refer to a metaprogram's input.
\end{notebox}

% Is a program in itself [lilis]
% allows code reuse at micro and macro level [savidis]

\subsection{Uses}
There are three main uses for metaprogramming: code optimization, code reuse, and analysis.

\paragraph{Code optimization}
A metaprogram can be used to make code run faster.
For example, with a Just-In-Time (JIT) compiler, a metaprogram can optimize blocks of code that are called more often than others \cite{hinsen_13_01} or caching the results of a method's call \cite{seaton_15_01}.
Another example is the use of Domain-Specific Languages (DSL). 
Here a metaprogram has a better understanding of the code and can apply optimizations the compiler might be unaware of - like knowing a value can never be negative \cite{hinsen_13_01}, simplifying an expression \cite{sheard_01_01}, or offloading to the GPU \cite{videau_18_01}.

\paragraph{Code reuse}
Metaprogramming can also be a code reuse tool.
Repeated code - like design patterns \cite{lilis_15_01, alexandrescu_01_01} - can be wrapped behind a metaprogram function that will write the reusable code \cite{savidis_19_01, klabnik_2019_01}.
Complex code can also be translated from a simpler language end-users might understand \cite{hinsen_13_01}.
The generated code can be anything from one-liners to classes \cite{savidis_19_01}.

\paragraph{Analysis}
Reading a program as input is the last use for a metaprogram.
After reading a program, the metaprogram can analyze its control flow, check types on a dynamic language, or building a proof theorem \cite{sheard_01_01}.

\subsection{Dimensions}
Metaprogramming comes in many dimensions.
This section will briefly focus on the relationship between the metalanguage and the output language, the model used for metaprogramming, when the metaprogram is executed, the location of the meta code, and how the final program is represented.
% TODO: maybe mention lee et al. here for cite problem

\subsubsection{Relation to the object language}
Metaprogramming will output code in some language.
The output language is called the object language, while the metaprogram is written in the metalanguage.
These two languages can be different or the same.
When they are the same, it is called a homogenous system.
If they are different, the system is called heterogeneous.
For a heterogeneous system, the metalanguage can extend the object language with extra features or be a completely new language. \cite{savidis_19_01, sheard_01_01}

%% Indistinguishable - recommended by spinellis & lilis

\subsubsection{Model}
Programming comes in different models ranging from procedural to functional to Object-oriented.
There should be no surprise to realize the same is true for metaprogramming.
These models follow.

\paragraph{Macro systems}
% TODO: question how to correctly cite this
A macro system takes input and expands it to some output. \cite{savidis_19_01}
The output can be another macro.
Thus expansion continues until no more macros are left.

The input can come in two forms.
First is the \textit{lexical macros}.
Here the input is just a stream of tokens.
These tokens can be anything and do not need to be any syntax.
The second form operates on a specific syntax and is called \textit{syntactic macros}.

Parsing the input can be procedural or pattern-based.
Procedural will use an algorithm to generate the output.
Patterns, on the other hand, will match an input pattern to its output.

\paragraph{Reflection systems}
Reflection is the process of an object to modify its structure.
This is commonly done at run-time but can also happen at compile-time \cite{savidis_19_01}.

\paragraph{Metaobject Protocol}
Rather than modifying an object's structure, Metaobject Protocol (MOP) also modifies an object's behavior.
This is done by inheriting from a metaclass that can modify its own behavior.
% TODO: cite
The modification then affects the subclasses. \cite{lee_95_01, savidis_19_01}
MOPs can also be used to modify a language's behavior \cite{seaton_15_01}.

\paragraph{Aspect-Oriented Programming}
Imagine wanting to add logging or performance metrics to all functions in a program.
Modifying each function will add a responsibility not part of the function's duties.
Then there is also the cost in time it will take to modify each function.
Aspect-Oriented Programming will \textit{weave} the extra responsibility - called \textit{advice} - into each function. \cite{savidis_19_01}

\paragraph{Generative Programming}
Generative programming is like a macro system.
The difference being that generative code is clearly not meta code to be expanded by the macro system.
They also typically represent their data as an Abstract Syntax Tree (AST). \cite{savidis_19_01}

\paragraph{Multistage Programming}
Lastly is the concept of having object code being generated in stages.
The multistage model does this.
The generations can be either automatic or require manual annotations. \cite{sheard_01_01, taha_04_01}

\subsubsection{Metaprogram execution}
Three options exist for when the metaprogram can be executed.

\paragraph{Before compilation}
The metaprogram can be executed before compilation.
This offers the option of using any language for the metaprogramming.
The metaprogram takes a source file with meta code and outputs a file without meta code. \cite{savidis_19_01}

\paragraph{During compilation}
Running the metaprogram as part of the compilation is another option.
This means the compiler needs to support metaprogramming, or it needs to have a plugin for metaprogramming. \cite{savidis_19_01}

\paragraph{Run-time}
Lastly, the metaprogram might execute at run-time.
This will require the language execution system to support dynamic code generation and execution. \cite{savidis_19_01}

\subsubsection{Meta code location}
The next dimension is the location of the meta code to be used as input to the metaprogram.
Two options exist.

\paragraph{External}
The meta code can be in an external file and will result in a new file with the object code.
% TODO: fourth repeat of 2nd sentence starting with this
This option is used with the before compilation option and generative model.
Alternatively, if this option is used with compilation time execution, then the file needs to be passed to the compiler with a flag. \cite{savidis_19_01}

\paragraph{Embedded}
The meta code can also be embedded with the program to transform.
This means a source file with a mixture of normal code and meta code.
Embedded code can have three levels of context-awareness. \cite{savidis_19_01}

\begin{itemize}
	\item Completely unaware: The meta code only relies on the input passed to it.
	      The code immediately after is not available to the metaprogram.
	\item Local awareness: The meta code relies not only on inputs but also on the code immediately after the meta code.
	\item Global awareness: The meta code relies on input and is aware of all code in the file.
\end{itemize}

\subsubsection{Data representation}
The final dimension to consider is the representation used to hold the final code.
Since the final code is the metaprogram's data \cite{bawden_99_01}, it needs to be held in some type.
Many systems use strings, graphs, or an algebraic data structure \cite{sheard_01_01}:

\paragraph{String}
The final program is held in a string.
This option is not desired since building a class may need hundreds of string append operations spanning hundreds of lines.
The object code interleaving with the metaprogram like this makes it hard to distinguish between the two.
It is thus easy to construct a string that is not syntactically correct.

\paragraph{Graphs}
A graph type will add some structure to the program being built.
Furthermore, it makes a better separation between the object code and the metaprogram code.
However, it still does not guarantee that the structure will be syntactically correct.

\paragraph{Algebraic}
Storing the data as an algebraic expression with type encoding or an AST is the only guarantee of a syntactically correct program.
However, building an AST by hand is hard.
Lisp solved this problem by using \textit{quasiquotes} \cite{bawden_99_01}.

\textit{Quasiquotes} is a form of templating.
It allows writing the data as a ``string'' (enclosed in backtick quotes) in the form of the object language.
This \textit{quoted} ``string'' is then transformed into the desired data structure.
Thus, it acts as a shortcut for constructing an AST \cite{lilis_15_01}.
Placeholders are placed in the \textit{quoted} ``string'' to be replaced with variables from the meta program context.
These placeholders need to be identifiable.
Thus, the placeholders are preceded by some \textit{unquote} character. \cite{bawden_99_01} \\

Having identified all the dimensions, let's identify the elements Rust uses for metaprogramming.

\subsection{Metaprogramming in Rust}
Rust has two metaprogramming functionalities build into the language.
The first has been with the language for some time and is meant for general metaprogramming.
The second is a newer addition added in late 2018 \footnote{https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html}.
It is called \textit{Procedural Macros} and is the only focus of this report. \cite{klabnik_2019_01}

The metalanguage for \textit{Procedural Macros} is Rust.
Thus, \textit{Procedural Macros} are homogenous.
From the name, it is also clear they follow the macro model, and the parsing is procedural.
The input stream is also a lexical token stream.
Whil, execution happens during compilation.
This means the macros need to be available to the compiler and thus need to be precompiled.
Thus, they need to be isolated from client code in a library marked for macro use \footnote{https://doc.rust-lang.org/reference/procedural-macros.html}.
The macro invocation is then embedded in the client code.
Since \textit{Procedural macros} come in three flavors, it has both local awareness or no awareness depending on the flavor used.
The data representation is the same as the input - a lexical token stream.

The input token stream does not need to be Rust code, but only the output stream.
Rust tries to keep its standard library as slim as possible while offloading features to libraries.
Given the wide range of possible inputs, it should not be a surprise that no standard library helpers exist for working with a token stream.
However, two Rust libraries do exist for working with tokens streams.

The first is \textit{syn}\footnote{https://docs.rs/syn/1.0.31/syn/index.html} for parsing Rust syntax to a syntax tree.
Other parsers can also be build using \textit{syn}.

The second is \textit{quote}\footnote{https://docs.rs/quote/1.0.7/quote/index.html} for generating a token stream from Rust syntax.
It is a macro that uses the quasiquotes concept from Lisp.
Thus, anything in the \textit{quoted} ``string'' is correctly highlighted, formatted, and autocompleted by an editor.

Let's discover the token stream, \textit{syn}, \textit{quote}, and the three flavors of \textit{Procedural Macros}.

\subsubsection{Procedural Macro flavors}
\colorlet{input}{Blue!10!}
\colorlet{context}{Red!10!}
\colorlet{output}{Green!10!}
\colorlet{function}{Yellow!40!}

The three flavors of Procedural Macros are function-like, derive, and attribute macros.

\paragraph{Function-like macros}
Function-like macros are the easiest flavor of procedural macros.
They take an input stream and return an output stream - i.e., they are context unaware.
\Fref{lst:Rust/function-like-macro} shows a reflective function-like macro that returns its input as is.

\embed{Reflective function-like macro}{Rust/function-like-macro}

Lines 1 and 2 import the \textit{proc\_macro} library and the \textit{TokenStream} type in the library.
These two lines will be needed for all macros and will not appear in future examples.
The \textit{\#[proc\_macro]} attribute on line 4 marks the function that follows as a function-like macro.
Line 5 shows it taking one \colorbox{input}{input} and returning one \colorbox{output}{output}.
On line 6, the input is returned unaltered.
Line 9 shows the line that will appear in client code to call the macro using the same \colorbox{function}{function name}.
All function macros are invoked using the \textit{!} (exclamation) sign - called the \textit{macro invocation operator} - to distinguish them from normal function calls.
Line 9 will be replaced with the \colorbox{output}{output} ``2 + 3, 5''.
Since the output is invalid Rust code, the compiler will give an error on line 9.

Notice how everything inside the parenthesis (\colorbox{input}{2 + 3, 5}) will be passed to \colorbox{input}{input}.
A \textit{TokenStream} can be thought of as a list of tokens.
There are four possible token types \footnote{https://doc.rust-lang.org/proc\_macro/enum.TokenTree.html}:

\begin{itemize}
	\item An \textit{Ident} to hold an identifier like a variable name.
	\item A \textit{Punct} to hold a single punctuation mark.
	\item A \textit{Literal} to hold a literal like an integer value.
	\item A \textit{Group} to hold an inner/nested \textit{TokenStream} surrounded by brackets.
\end{itemize}

Thus the 2, 3, and 5 will be literal tokens.
The +(plus) sign and ,(comma) will be punctuations in both streams.
Again, parsing and generating the list will be hard.
Thus, the next example shows how to use the \textit{syn} and \textit{quote} libraries to make this easier.

\paragraph{Derive macros}
Derive macros are used to add methods to objects as seen in \Fref{lst:Rust/derive-macro}.

\embed[firstline=4]{Derive macro example}{Rust/derive-macro}

Line 1 shows the import for the \textit{syn} library to parse the input list of tokens to a syntax tree.
Derive macros have the \textit{proc\_macro\_derive} attribute followed by the macro \colorbox{function}{name} as seen on line 3.
The \colorbox{context}{input} on line 4 is the context the macro is called on.
Thus, derive macros have local context-awareness.
The \colorbox{context}{context} is line 20.

Line 5 parses the context to a \textit{DerivedInput} syntax tree from \textit{syn}.
\textit{Syn} will give a compilation error if the parsing fails.
Getting the struct name happens on line 6.

Lines 8 to 14 show the use of the \textit{quote} library for quasiquotes.
Rather than a \textit{quoted} ``string'', it uses the \textit{quote} macro.
Placeholders are marked with the \# (pound) sign.
Notice the syntax highlighting being correct inside the quote macro.
Finally, line 16 converts the output to a \textit{TokenStream}.

The macro is used on line 19 as an attribute on an object.
The compiler will write line 21.
Thus derive macros append code below the annotated type.

\paragraph{Attribute macros}
Attribute macros are like function-like macros with context-awareness.
Therefore, two token streams are passed to them as seen in \Fref{lst:Rust/attribute-macro}.

\embed{Attribute macro example}{Rust/attribute-macro}

This time the attribute above the function is \textit{proc\_macro\_attribute}.
The function \colorbox{function}{name} serves as the attribute name where it is used on line 9.
The \colorbox{input}{input} is the first stream passed to the function, while the \colorbox{context}{context} is the second.
Like function macros, the \colorbox{context}{context} on line 10 will be replaced with the \colorbox{output}{output}.

Since the metalanguage is Rust code, it is time to learn more about Rust.

% Can be a blunt instrument [spinellis]
% Language designed with meta-programming [spinellis]

%%% (My objectives)
% Should be same as human code [spinellis]
% Source browsing [lilis]
%% Editing support [lilis p761]
% Should be correct - or at least friendly messages [spinellis]
% Debugger integration [lilis]
% Usage should be easy to read [spinellis]
